{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49rrMWKJZdBR",
      "metadata": {
        "id": "49rrMWKJZdBR"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I9KT7uZGZejo",
      "metadata": {
        "id": "I9KT7uZGZejo"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tT7ft38DZ-OL",
      "metadata": {
        "id": "tT7ft38DZ-OL"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c equity-post-HCT-survival-predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lJpyMJkpaCe4",
      "metadata": {
        "id": "lJpyMJkpaCe4"
      },
      "outputs": [],
      "source": [
        "!unzip equity-post-HCT-survival-predictions.zip -d equity-post-HCT-survival-predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QZ1MRt_HbSbz",
      "metadata": {
        "id": "QZ1MRt_HbSbz"
      },
      "outputs": [],
      "source": [
        "!pip install lifelines\n",
        "!pip install autograd\n",
        "!pip install formulaic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e19ffc",
      "metadata": {
        "id": "89e19ffc"
      },
      "outputs": [],
      "source": [
        "!pip install /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n",
        "!pip install /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n",
        "!pip install /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n",
        "!pip install /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n",
        "!pip install /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6c48439",
      "metadata": {
        "id": "e6c48439"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "To evaluate the equitable prediction of transplant survival outcomes,\n",
        "we use the concordance index (C-index) between a series of event\n",
        "times and a predicted score across each race group.\n",
        "\n",
        "It represents the global assessment of the model discrimination power:\n",
        "this is the model’s ability to correctly provide a reliable ranking\n",
        "of the survival times based on the individual risk scores.\n",
        "\n",
        "The concordance index is a value between 0 and 1 where:\n",
        "\n",
        "0.5 is the expected result from random predictions,\n",
        "1.0 is perfect concordance (with no censoring, otherwise <1.0),\n",
        "0.0 is perfect anti-concordance (with no censoring, otherwise >0.0)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import pandas.api.types\n",
        "import numpy as np\n",
        "from lifelines.utils import concordance_index\n",
        "\n",
        "class ParticipantVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
        "    \"\"\"\n",
        "    >>> import pandas as pd\n",
        "    >>> row_id_column_name = \"id\"\n",
        "    >>> y_pred = {'prediction': {0: 1.0, 1: 0.0, 2: 1.0}}\n",
        "    >>> y_pred = pd.DataFrame(y_pred)\n",
        "    >>> y_pred.insert(0, row_id_column_name, range(len(y_pred)))\n",
        "    >>> y_true = { 'efs': {0: 1.0, 1: 0.0, 2: 0.0}, 'efs_time': {0: 25.1234,1: 250.1234,2: 2500.1234}, 'race_group': {0: 'race_group_1', 1: 'race_group_1', 2: 'race_group_1'}}\n",
        "    >>> y_true = pd.DataFrame(y_true)\n",
        "    >>> y_true.insert(0, row_id_column_name, range(len(y_true)))\n",
        "    >>> score(y_true.copy(), y_pred.copy(), row_id_column_name)\n",
        "    0.75\n",
        "    \"\"\"\n",
        "\n",
        "    del solution[row_id_column_name]\n",
        "    del submission[row_id_column_name]\n",
        "\n",
        "    event_label = 'efs'\n",
        "    interval_label = 'efs_time'\n",
        "    prediction_label = 'prediction'\n",
        "    for col in submission.columns:\n",
        "        if not pandas.api.types.is_numeric_dtype(submission[col]):\n",
        "            raise ParticipantVisibleError(f'Submission column {col} must be a number')\n",
        "    # Merging solution and submission dfs on ID\n",
        "    merged_df = pd.concat([solution, submission], axis=1)\n",
        "    merged_df.reset_index(inplace=True)\n",
        "    merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n",
        "    metric_list = []\n",
        "    for race in merged_df_race_dict.keys():\n",
        "        # Retrieving values from y_test based on index\n",
        "        indices = sorted(merged_df_race_dict[race])\n",
        "        merged_df_race = merged_df.iloc[indices]\n",
        "        # Calculate the concordance index\n",
        "        c_index_race = concordance_index(\n",
        "                        merged_df_race[interval_label],\n",
        "                        -merged_df_race[prediction_label],\n",
        "                        merged_df_race[event_label])\n",
        "        metric_list.append(c_index_race)\n",
        "    return float(np.mean(metric_list)-np.sqrt(np.var(metric_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10eb3428",
      "metadata": {
        "id": "10eb3428"
      },
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.max_rows', 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2cce31e",
      "metadata": {
        "id": "e2cce31e"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(\"/content/equity-post-HCT-survival-predictions/test.csv\")\n",
        "print(\"Test shape:\", test.shape )\n",
        "\n",
        "\n",
        "train = pd.read_csv(\"/content/equity-post-HCT-survival-predictions/train.csv\")\n",
        "print(\"Train shape:\",train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d305fe7a",
      "metadata": {
        "id": "d305fe7a"
      },
      "outputs": [],
      "source": [
        "from lifelines import KaplanMeierFitter, NelsonAalenFitter\n",
        "\n",
        "def transform_kmf(df, time_col='efs_time', event_col='efs'):\n",
        "    \"\"\"\n",
        "    Transform using survival probability estimates\n",
        "    \"\"\"\n",
        "    kmf = KaplanMeierFitter()\n",
        "    kmf.fit(df[time_col], df[event_col])\n",
        "    y = kmf.survival_function_at_times(df[time_col]).values\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74163f68",
      "metadata": {
        "id": "74163f68"
      },
      "outputs": [],
      "source": [
        "train['y'] = transform_kmf(train, 'efs_time', 'efs')\n",
        "\n",
        "# try adding -0.1\n",
        "train.loc[train['efs'] == 0, 'y'] -= 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f6aac98",
      "metadata": {
        "id": "6f6aac98"
      },
      "outputs": [],
      "source": [
        "to_rmv =['ID', 'efs', 'efs_time', 'y']\n",
        "features = [col for col in train.columns if not col in to_rmv]\n",
        "cat = [c for c in features if train[c].dtype == 'object']\n",
        "num = [c for c in features if train[c].dtype != 'object']\n",
        "target = 'y'\n",
        "print(f'There are {len(features)} features')\n",
        "print(f'There are {len(cat)} for catagorial and {len(num)} for numerical')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d329d335",
      "metadata": {
        "id": "d329d335"
      },
      "source": [
        "*italicised text*# Feature eng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfd093ec",
      "metadata": {
        "id": "dfd093ec"
      },
      "outputs": [],
      "source": [
        "for c in cat:\n",
        "    train[c].fillna('Missing', inplace=True)\n",
        "    test[c].fillna('Missing', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40f8cd7c",
      "metadata": {
        "id": "40f8cd7c"
      },
      "outputs": [],
      "source": [
        "def convert_64_to_32(df, num_features):\n",
        "    for c in num_features:\n",
        "        if df[c].dtype == 'float64':\n",
        "            df[c] = df[c].astype('float32')\n",
        "        else:\n",
        "            df[c] = df[c].astype('int32')\n",
        "    return df\n",
        "\n",
        "train = convert_64_to_32(train, num)\n",
        "test = convert_64_to_32(test, num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a7d9b98",
      "metadata": {
        "id": "0a7d9b98"
      },
      "outputs": [],
      "source": [
        "def clean_columns(df):\n",
        "\n",
        "    value_mappings = {\n",
        "        'cmv_status': {\n",
        "            '+/+': 'Positive_Positive',\n",
        "            '+/-': 'Positive_Negative',\n",
        "            '-/+': 'Negative_Positive',\n",
        "            '-/-': 'Negative_Negative'\n",
        "        },\n",
        "        'tbi_status': {\n",
        "            'No TBI': 'No_Total_Body_Irradiation',\n",
        "            'TBI + Cy +- Other': 'TBI_with_Cyclophosphamide_and_Other',\n",
        "            'TBI +- Other, <=cGy': 'TBI_with_Other_Low_Dose',\n",
        "            'TBI +- Other, >cGy': 'TBI_with_Other_High_Dose',\n",
        "            'TBI +- Other, -cGy, single': 'TBI_with_Other_Single_Dose',\n",
        "            'TBI +- Other, unknown dose': 'TBI_with_Other_Unknown_Dose',\n",
        "            'TBI +- Other, -cGy, unknown dose': 'TBI_with_Other_Unknown_Dose',\n",
        "            'TBI +- Other, -cGy, fractionated': 'TBI_with_Other_Fractionated_Dose'\n",
        "        },\n",
        "        'dri_score': {\n",
        "            'Intermediate': 'Intermediate_Risk',\n",
        "            'N/A - pediatric': 'Not_Applicable_Pediatric',\n",
        "            'High': 'High_Risk',\n",
        "            'N/A - non-malignant indication': 'Not_Applicable_Non_Malignant',\n",
        "            'TBD cytogenetics': 'To_Be_Determined_Cytogenetics',\n",
        "            'Low': 'Low_Risk',\n",
        "            'High - TED AML case <missing cytogenetics': 'High_Risk_TED_AML_Missing_Cytogenetics',\n",
        "            'Intermediate - TED AML case <missing cytogenetics': 'Intermediate_Risk_TED_AML_Missing_Cytogenetics',\n",
        "            'N/A - disease not classifiable': 'Not_Applicable_Disease_Not_Classifiable',\n",
        "            'Very high': 'Very_High_Risk',\n",
        "            'Missing disease status': 'Missing'\n",
        "        },\n",
        "        'tce_imm_match': {\n",
        "            'P/P': 'Perfect_Perfect',\n",
        "            'G/G': 'Good_Good',\n",
        "            'H/H': 'Heterozygous_Heterozygous',\n",
        "            'G/B': 'Good_Bad',\n",
        "            'H/B': 'Heterozygous_Bad',\n",
        "            'P/H': 'Perfect_Heterozygous',\n",
        "            'P/B': 'Perfect_Bad',\n",
        "            'P/G': 'Perfect_Good'\n",
        "        },\n",
        "        'gvhd_proph': {\n",
        "            'FK+ MMF +- others': 'Tacrolimus_MMF_with_Others',\n",
        "            'Cyclophosphamide alone': 'Cyclophosphamide_Alone',\n",
        "            'FK+ MTX +- others(not MMF)': 'Tacrolimus_MTX_with_Others_Not_MMF',\n",
        "            'Cyclophosphamide +- others': 'Cyclophosphamide_with_Others',\n",
        "            'CSA + MMF +- others(not FK)': 'Cyclosporine_MMF_with_Others_Not_Tacrolimus',\n",
        "            'FKalone': 'Tacrolimus_Alone',\n",
        "            'Other GVHD Prophylaxis': 'Other_GVHD_Prophylaxis',\n",
        "            'TDEPLETION alone': 'TCell_Depletion_Alone',\n",
        "            'TDEPLETION +- other': 'TCell_Depletion_with_Others',\n",
        "            'No GvHD Prophylaxis': 'No_GVHD_Prophylaxis',\n",
        "            'CDselect alone': 'CD_Selection_Alone',\n",
        "            'CSA + MTX +- others(not MMF,FK)': 'Cyclosporine_MTX_with_Others_Not_MMF_Tacrolimus',\n",
        "            'CSA alone': 'Cyclosporine_Alone',\n",
        "            'Parent Q = yes, but no agent': 'Parent_Yes_No_Agent',\n",
        "            'CDselect +- other': 'CD_Selection_with_Others',\n",
        "            'CSA +- others(not FK,MMF,MTX)': 'Cyclosporine_with_Others_Not_Tacrolimus_MMF_MTX',\n",
        "            'FK+- others(not MMF,MTX)': 'Tacrolimus_with_Others_Not_MMF_MTX'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for col, mappings in value_mappings.items():\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(str).map(mappings).fillna(df[col])\n",
        "\n",
        "    return df\n",
        "\n",
        "def clean_space(df):\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        df[col] = df[col].apply(lambda x: x.replace(' ', '_') if isinstance(x, str) else x)\n",
        "    return df\n",
        "\n",
        "def clean_not_done(df):\n",
        "    df = df.map(lambda x: 'Missing' if x == 'Not done' else x)\n",
        "    return df\n",
        "\n",
        "def clean_not_tested(df):\n",
        "    df = df.map(lambda x: 'Missing' if x == 'Not tested' else x)\n",
        "    return df\n",
        "\n",
        "def clean_dri_score(score):\n",
        "    if isinstance(score, str) and 'Missing disease status' in score:\n",
        "        return 'Missing'\n",
        "    return score\n",
        "\n",
        "def clean_conditioning_intensity(score):\n",
        "    if isinstance(score, str) and 'No drugs reported' in score:\n",
        "        return 'Missing'\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18478e75",
      "metadata": {
        "id": "18478e75"
      },
      "outputs": [],
      "source": [
        "train = clean_columns(train)\n",
        "test = clean_columns(test)\n",
        "\n",
        "# train = clean_not_done(train)\n",
        "# test = clean_not_done(test)\n",
        "\n",
        "# train = clean_not_tested(train)\n",
        "# test = clean_not_tested(test)\n",
        "\n",
        "train['dri_score'] = train['dri_score'].apply(clean_dri_score)\n",
        "test['dri_score'] = test['dri_score'].apply(clean_dri_score)\n",
        "\n",
        "train['conditioning_intensity'] = train['conditioning_intensity'].apply(clean_conditioning_intensity)\n",
        "test['conditioning_intensity'] = test['conditioning_intensity'].apply(clean_conditioning_intensity)\n",
        "\n",
        "train = clean_space(train)\n",
        "test = clean_space(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fb3873e",
      "metadata": {
        "id": "9fb3873e"
      },
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a963c66",
      "metadata": {
        "id": "1a963c66"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "def encode_features_lgb(train, test, cat, num):\n",
        "    train = train.copy()\n",
        "    test = test.copy()\n",
        "\n",
        "    for c in cat:\n",
        "        encoder = LabelEncoder()\n",
        "\n",
        "        # Fit and transform the training data\n",
        "        train[c] = train[c].astype(str)\n",
        "        train[c] = encoder.fit_transform(train[c])\n",
        "        train[c] = train[c].astype('int32').astype('category')\n",
        "\n",
        "        # Transform the test data using the encoder fitted on the training data\n",
        "        test[c] = test[c].astype(str)\n",
        "        test[c] = encoder.transform(test[c])\n",
        "        test[c] = test[c].astype('int32').astype('category')\n",
        "\n",
        "    return train, test\n",
        "\n",
        "train_lgb, test_lgb = encode_features_lgb(train, test, cat, num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22f5d62c",
      "metadata": {
        "id": "22f5d62c"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
        "from sklearn.metrics import *\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "def train_lgbm(train, test, model_params, features, cat_features, target):\n",
        "\n",
        "    fix_params = {\n",
        "        'n_estimators': 10000,\n",
        "        'objective': 'regression',\n",
        "        'early_stopping_rounds':20,\n",
        "        'verbose': -1\n",
        "    }\n",
        "    model_params.update(fix_params)\n",
        "\n",
        "    FOLDS = 10\n",
        "    kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "    oof_lgb = np.zeros(len(train))\n",
        "    pred_lgb = np.zeros(len(test))\n",
        "\n",
        "    print('Training model with the followin parameters')\n",
        "    for k, v in model_params.items():\n",
        "        print(f'{k} : {v}')\n",
        "\n",
        "    for i, (t_idx, v_idx) in enumerate(kf.split(train)):\n",
        "\n",
        "        X_train = train.iloc[t_idx][features].copy()\n",
        "        y_train = train.iloc[t_idx][target]\n",
        "        X_valid = train.iloc[v_idx][features].copy()\n",
        "        y_valid = train.iloc[v_idx][target]\n",
        "        X_test = test[features].copy()\n",
        "\n",
        "        model_lgb = LGBMRegressor(**model_params)\n",
        "        model_lgb.fit(\n",
        "            X_train, np.log1p(y_train),\n",
        "            eval_set=[(X_valid, np.log1p(y_valid))],\n",
        "        )\n",
        "\n",
        "        y_valid_preds = np.expm1(model_lgb.predict(X_valid))\n",
        "        oof_lgb[v_idx] = y_valid_preds\n",
        "        pred_lgb += np.expm1(model_lgb.predict(X_test))\n",
        "\n",
        "\n",
        "        fold_rmse = np.sqrt(mean_squared_error(y_valid, y_valid_preds))\n",
        "        print(\"#\"*25)\n",
        "        print(f\"### Fold {i+1} \\n\")\n",
        "        print(f\"Fold {i+1} RMSE: {fold_rmse}\")\n",
        "        print(\"#\"*25)\n",
        "\n",
        "    pred_lgb /= FOLDS\n",
        "\n",
        "    return model_lgb, oof_lgb, pred_lgb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ac9f56d",
      "metadata": {
        "id": "1ac9f56d"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4fc1048",
      "metadata": {
        "id": "b4fc1048"
      },
      "outputs": [],
      "source": [
        "def encode_features_xgb(train, test, label_encode_features, one_hot_encode_features, features):\n",
        "\n",
        "    # Label Encoding\n",
        "    label_encoders = {}\n",
        "    for feature in label_encode_features:\n",
        "        encoder = LabelEncoder()\n",
        "        train[feature] = train[feature].astype(str)\n",
        "        train[feature] = encoder.fit_transform(train[feature])\n",
        "        test[feature] = test[feature].astype(str)\n",
        "        test[feature] = encoder.transform(test[feature])\n",
        "        label_encoders[feature] = encoder\n",
        "\n",
        "    # One-Hot Encoding\n",
        "    train_one_hot = pd.get_dummies(train[one_hot_encode_features], prefix=one_hot_encode_features)\n",
        "    test_one_hot = pd.get_dummies(test[one_hot_encode_features], prefix=one_hot_encode_features)\n",
        "\n",
        "    train_one_hot, test_one_hot = train_one_hot.align(test_one_hot, join=\"outer\", axis=1, fill_value=0)\n",
        "\n",
        "    train_xgb = pd.concat([train, train_one_hot], axis=1)\n",
        "    test_xgb = pd.concat([test, test_one_hot], axis=1)\n",
        "\n",
        "    features_xgb = features.copy()\n",
        "    features_xgb.extend(train_one_hot.columns)\n",
        "    features_xgb = [f for f in features_xgb if f not in one_hot_encode_features]\n",
        "\n",
        "    return train_xgb, test_xgb, features_xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a87c752",
      "metadata": {
        "id": "5a87c752"
      },
      "outputs": [],
      "source": [
        "# Define features for label and one-hot encoding\n",
        "label_encode_features = [\n",
        "    \"dri_score\", \"psych_disturb\", \"cyto_score\", \"diabetes\",\n",
        "    \"arrhythmia\", \"vent_hist\", \"renal_issue\", \"pulm_severe\",\n",
        "    \"cmv_status\", \"tce_imm_match\", \"rituximab\", \"cyto_score_detail\",\n",
        "    \"conditioning_intensity\", \"ethnicity\", \"obesity\", \"mrd_hct\",\n",
        "    \"in_vivo_tcd\", \"tce_match\", \"hepatic_severe\", \"prior_tumor\",\n",
        "    \"peptic_ulcer\", \"gvhd_proph\", \"rheum_issue\", \"sex_match\",\n",
        "    \"hepatic_mild\", \"tce_div_match\", \"donor_related\", \"melphalan_dose\",\n",
        "    \"cardiac\", \"pulm_moderate\"\n",
        "]\n",
        "\n",
        "one_hot_encode_features = [\n",
        "    \"tbi_status\", \"graft_type\", \"prod_type\", \"prim_disease_hct\", \"race_group\"\n",
        "]\n",
        "\n",
        "# Apply the encoding\n",
        "train_xgb, test_xgb, features_xgb = encode_features_xgb(train, test, label_encode_features, one_hot_encode_features, features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4a62719",
      "metadata": {
        "id": "b4a62719"
      },
      "outputs": [],
      "source": [
        "def object_to_cat(df):\n",
        "    for col in df.select_dtypes(include='object').columns:\n",
        "        df[col] = df[col].astype('category')\n",
        "    return df\n",
        "train_xgb2 = object_to_cat(train)\n",
        "test_xgb2 = object_to_cat(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ef0769",
      "metadata": {
        "id": "71ef0769"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "def train_XGB(train, test, model_params, features, target):\n",
        "    fix_params = {\n",
        "        'tree_method': 'hist',\n",
        "        'device': 'cuda',\n",
        "        'objective': 'reg:squarederror',\n",
        "        'n_estimators': 10000,\n",
        "        'early_stopping_rounds': 20,\n",
        "        'eval_metric': 'rmse',\n",
        "        'enable_categorical': True\n",
        "    }\n",
        "    model_params.update(fix_params)\n",
        "\n",
        "    FOLDS = 10\n",
        "    kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "    oof_xgb = np.zeros(len(train))\n",
        "    pred_xgb = np.zeros(len(test))\n",
        "\n",
        "    print('Training XGBoost model with the following parameters:')\n",
        "    for k, v in model_params.items():\n",
        "        print(f'{k} : {v}')\n",
        "\n",
        "    for i, (t_idx, v_idx) in enumerate(kf.split(train)):\n",
        "        X_train = train.iloc[t_idx][features].copy()\n",
        "        y_train = train.iloc[t_idx][target]\n",
        "        X_valid = train.iloc[v_idx][features].copy()\n",
        "        y_valid = train.iloc[v_idx][target]\n",
        "        X_test = test[features].copy()\n",
        "\n",
        "        model_xgb = XGBRegressor(**model_params)\n",
        "        model_xgb.fit(\n",
        "            X_train, np.log1p(y_train),\n",
        "            eval_set=[(X_valid, np.log1p(y_valid))],\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        y_valid_preds = np.expm1(model_xgb.predict(X_valid))\n",
        "        oof_xgb[v_idx] = y_valid_preds\n",
        "        pred_xgb += np.expm1(model_xgb.predict(X_test))\n",
        "\n",
        "        fold_rmse = np.sqrt(mean_squared_error(y_valid, y_valid_preds))\n",
        "        print(\"#\" * 25)\n",
        "        print(f\"### Fold {i+1} \\n\")\n",
        "        print(f\"Fold {i+1} RMSE: {fold_rmse}\")\n",
        "        print(\"#\" * 25)\n",
        "\n",
        "    pred_xgb /= FOLDS\n",
        "\n",
        "    return model_xgb, oof_xgb, pred_xgb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61955223",
      "metadata": {
        "id": "61955223"
      },
      "source": [
        "# CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "336e6f1b",
      "metadata": {
        "id": "336e6f1b"
      },
      "outputs": [],
      "source": [
        "train_cat = train.copy()\n",
        "test_cat = test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sa6VDar-kYlB",
      "metadata": {
        "id": "sa6VDar-kYlB"
      },
      "outputs": [],
      "source": [
        "!pip install catboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdf811b2",
      "metadata": {
        "id": "fdf811b2"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostRegressor\n",
        "\n",
        "def train_CAT(train, test, model_params, features, cat_features, target):\n",
        "    fix_params = {\n",
        "        'task_type': \"GPU\",\n",
        "        'iterations': 10000,\n",
        "        'loss_function': 'RMSE',\n",
        "        'early_stopping_rounds': 20,\n",
        "    }\n",
        "    model_params.update(fix_params)\n",
        "\n",
        "    FOLDS = 10\n",
        "    kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "    oof_cat = np.zeros(len(train))\n",
        "    pred_cat = np.zeros(len(test))\n",
        "\n",
        "    print('Training model with the following parameters')\n",
        "    for k, v in model_params.items():\n",
        "        print(f'{k} : {v}')\n",
        "\n",
        "    for i, (t_idx, v_idx) in enumerate(kf.split(train)):\n",
        "        X_train = train.iloc[t_idx][features].copy()\n",
        "        y_train = train.iloc[t_idx][target]\n",
        "        X_valid = train.iloc[v_idx][features].copy()\n",
        "        y_valid = train.iloc[v_idx][target]\n",
        "        X_test = test[features].copy()\n",
        "\n",
        "\n",
        "        model_cat = CatBoostRegressor(**model_params)\n",
        "        model_cat.fit(\n",
        "            X_train, np.log1p(y_train),\n",
        "            cat_features=cat_features,\n",
        "            eval_set=[(X_valid, np.log1p(y_valid))],\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        y_valid_preds = np.expm1(model_cat.predict(X_valid))\n",
        "        oof_cat[v_idx] = y_valid_preds\n",
        "        pred_cat += np.expm1(model_cat.predict(X_test))\n",
        "\n",
        "        fold_rmse = mean_squared_error(y_valid, y_valid_preds, squared=False)\n",
        "        print(\"#\" * 25)\n",
        "        print(f\"### Fold {i + 1} \\n\")\n",
        "        print(f\"Fold {i + 1} RMSE: {fold_rmse}\")\n",
        "        print(\"#\" * 25)\n",
        "\n",
        "    pred_cat /= FOLDS\n",
        "\n",
        "    return model_cat, oof_cat, pred_cat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WpofFzo4LFfv",
      "metadata": {
        "id": "WpofFzo4LFfv"
      },
      "source": [
        "random for\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W3uJBBCQLG6P",
      "metadata": {
        "id": "W3uJBBCQLG6P"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "def train_RF(train, test, model_params, features, target):\n",
        "    FOLDS = 10\n",
        "    kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "    oof_rf = np.zeros(len(train))\n",
        "    pred_rf = np.zeros(len(test))\n",
        "\n",
        "    for i, (t_idx, v_idx) in enumerate(kf.split(train)):\n",
        "        X_train = train.iloc[t_idx][features]\n",
        "        y_train = train.iloc[t_idx][target]\n",
        "        X_valid = train.iloc[v_idx][features]\n",
        "        y_valid = train.iloc[v_idx][target]\n",
        "        X_test = test[features]\n",
        "\n",
        "        model_rf = RandomForestRegressor(**model_params)\n",
        "        model_rf.fit(X_train, np.log1p(y_train))\n",
        "\n",
        "        y_valid_preds = np.expm1(model_rf.predict(X_valid))\n",
        "        oof_rf[v_idx] = y_valid_preds\n",
        "        pred_rf += np.expm1(model_rf.predict(X_test))\n",
        "\n",
        "        fold_rmse = mean_squared_error(y_valid, y_valid_preds, squared=False)\n",
        "        print(\"#\" * 25)\n",
        "        print(f\"### Fold {i + 1} \\n\")\n",
        "        print(f\"Fold {i + 1} RMSE: {fold_rmse}\")\n",
        "        print(\"#\" * 25)\n",
        "\n",
        "    pred_rf /= FOLDS\n",
        "\n",
        "    return model_rf, oof_rf, pred_rf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pogTLOoNLLQz",
      "metadata": {
        "id": "pogTLOoNLLQz"
      },
      "source": [
        "HistGradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2n1veCXLLIlJ",
      "metadata": {
        "id": "2n1veCXLLIlJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "\n",
        "def train_HGB(train, test, model_params, features, target):\n",
        "    FOLDS = 10\n",
        "    kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "    oof_hgb = np.zeros(len(train))\n",
        "    pred_hgb = np.zeros(len(test))\n",
        "\n",
        "    for i, (t_idx, v_idx) in enumerate(kf.split(train)):\n",
        "        X_train = train.iloc[t_idx][features]\n",
        "        y_train = train.iloc[t_idx][target]\n",
        "        X_valid = train.iloc[v_idx][features]\n",
        "        y_valid = train.iloc[v_idx][target]\n",
        "        X_test = test[features]\n",
        "\n",
        "        model_hgb = HistGradientBoostingRegressor(**model_params)\n",
        "        model_hgb.fit(X_train, np.log1p(y_train))\n",
        "\n",
        "        y_valid_preds = np.expm1(model_hgb.predict(X_valid))\n",
        "        oof_hgb[v_idx] = y_valid_preds\n",
        "        pred_hgb += np.expm1(model_hgb.predict(X_test))\n",
        "\n",
        "        fold_rmse = mean_squared_error(y_valid, y_valid_preds, squared=False)\n",
        "        print(\"#\" * 25)\n",
        "        print(f\"### Fold {i + 1} \\n\")\n",
        "        print(f\"Fold {i + 1} RMSE: {fold_rmse}\")\n",
        "        print(\"#\" * 25)\n",
        "\n",
        "    pred_hgb /= FOLDS\n",
        "\n",
        "    return model_hgb, oof_hgb, pred_hgb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rjhXT5uPLN1V",
      "metadata": {
        "id": "rjhXT5uPLN1V"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b9c7af9e",
      "metadata": {
        "id": "b9c7af9e"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc3caef3",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cc3caef3"
      },
      "outputs": [],
      "source": [
        "# Model parameters\n",
        "model_lgb_params = {\n",
        "    'max_depth': 5,\n",
        "    'learning_rate': 0.01,\n",
        "    'colsample_bytree': 0.40481123886709114,\n",
        "    'subsample': 0.7673666426617842,\n",
        "    'num_leaves': 46,\n",
        "    'min_child_samples': 34,\n",
        "    'lambda_l1': 0.0032893870728708495,\n",
        "    'lambda_l2': 1.5780171816002318e-06,\n",
        "    'bagging_freq': 5,\n",
        "    'cat_features': cat,\n",
        "    'n_estimators': 5000,\n",
        "    'objective': 'regression',\n",
        "    'early_stopping_rounds': 20\n",
        "}\n",
        "\n",
        "model_xgb_params = {\n",
        "    'max_depth': 4,\n",
        "    'learning_rate': 0.09180807102095336,\n",
        "    'colsample_bytree': 0.3809438487844099,\n",
        "    'subsample': 0.844622438351228,\n",
        "    'n_estimators': 419,\n",
        "    'min_child_weight': 3.714743419003562,\n",
        "    'reg_alpha': 5.80197653137552e-06,\n",
        "    'reg_lambda': 1.2374095115455325e-08,\n",
        "    'gamma': 0.0037460722016019465\n",
        "}\n",
        "\n",
        "model_xgb2_params = {\n",
        "    \"max_depth\": 9,\n",
        "    \"learning_rate\": 0.018203874021653552,\n",
        "    \"colsample_bytree\": 0.41392312362600636,\n",
        "    \"subsample\": 0.870771567534879,\n",
        "    \"n_estimators\": 10000,\n",
        "    \"min_child_weight\": 6.587958958652532,\n",
        "    \"reg_alpha\": 1.675358492618636e-07,\n",
        "    \"reg_lambda\": 0.004228750471811781,\n",
        "    \"gamma\": 0.02009243264106564,\n",
        "    \"tree_method\": \"gpu_hist\",\n",
        "    \"objective\": \"reg:squarederror\",\n",
        "    \"early_stopping_rounds\": 20,\n",
        "    \"eval_metric\": \"rmse\",\n",
        "    \"enable_categorical\": True\n",
        "}\n",
        "\n",
        "model_cat_params = {\n",
        "    'depth': 5,\n",
        "    'learning_rate': 0.05259516359861675,\n",
        "    'bagging_temperature': 0.5,\n",
        "    'l2_leaf_reg': 6.806823646372654e-06,\n",
        "    'random_strength': 5.889614035287661\n",
        "}\n",
        "\n",
        "# === New models imports ===\n",
        "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# === Encoding for RandomForest and HistGBD ===\n",
        "train_rf = train.copy()\n",
        "test_rf = test.copy()\n",
        "\n",
        "for col in features:\n",
        "    if train_rf[col].dtype == \"object\" or str(train_rf[col].dtype).startswith('category'):\n",
        "        le = LabelEncoder()\n",
        "        train_rf[col] = le.fit_transform(train_rf[col].astype(str))\n",
        "        test_rf[col] = le.transform(test_rf[col].astype(str))\n",
        "\n",
        "# === Functions ===\n",
        "def train_random_forest(train, test, features, target):\n",
        "    FOLDS = 10\n",
        "    kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "    oof_rf = np.zeros(len(train))\n",
        "    pred_rf = np.zeros(len(test))\n",
        "\n",
        "    for i, (t_idx, v_idx) in enumerate(kf.split(train)):\n",
        "        X_train = train.iloc[t_idx][features]\n",
        "        y_train = train.iloc[t_idx][target]\n",
        "        X_valid = train.iloc[v_idx][features]\n",
        "        y_valid = train.iloc[v_idx][target]\n",
        "        X_test = test[features]\n",
        "\n",
        "        model_rf = RandomForestRegressor(\n",
        "            n_estimators=500,\n",
        "            max_depth=10,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        model_rf.fit(X_train, y_train)\n",
        "\n",
        "        y_valid_preds = model_rf.predict(X_valid)\n",
        "        oof_rf[v_idx] = y_valid_preds\n",
        "        pred_rf += model_rf.predict(X_test)\n",
        "\n",
        "        fold_rmse = np.sqrt(mean_squared_error(y_valid, y_valid_preds))\n",
        "        print(f\"RF Fold {i+1} RMSE: {fold_rmse}\")\n",
        "\n",
        "    pred_rf /= FOLDS\n",
        "    return model_rf, oof_rf, pred_rf\n",
        "\n",
        "\n",
        "def train_hist_gbdt(train, test, features, target):\n",
        "    FOLDS = 10\n",
        "    kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "    oof_hist = np.zeros(len(train))\n",
        "    pred_hist = np.zeros(len(test))\n",
        "\n",
        "    for i, (t_idx, v_idx) in enumerate(kf.split(train)):\n",
        "        X_train = train.iloc[t_idx][features]\n",
        "        y_train = train.iloc[t_idx][target]\n",
        "        X_valid = train.iloc[v_idx][features]\n",
        "        y_valid = train.iloc[v_idx][target]\n",
        "        X_test = test[features]\n",
        "\n",
        "        model_hist = HistGradientBoostingRegressor(\n",
        "            learning_rate=0.05,\n",
        "            max_iter=1000,\n",
        "            max_depth=6,\n",
        "            random_state=42\n",
        "        )\n",
        "        model_hist.fit(X_train, y_train)\n",
        "\n",
        "        y_valid_preds = model_hist.predict(X_valid)\n",
        "        oof_hist[v_idx] = y_valid_preds\n",
        "        pred_hist += model_hist.predict(X_test)\n",
        "\n",
        "        fold_rmse = np.sqrt(mean_squared_error(y_valid, y_valid_preds))\n",
        "        print(f\"HistGBDT Fold {i+1} RMSE: {fold_rmse}\")\n",
        "\n",
        "    pred_hist /= FOLDS\n",
        "    return model_hist, oof_hist, pred_hist\n",
        "\n",
        "# ======= Train all models ========\n",
        "model_rf, oof_rf, pred_rf = train_random_forest(train_rf, test_rf, features, target)\n",
        "model_hist, oof_hist, pred_hist = train_hist_gbdt(train_rf, test_rf, features, target)\n",
        "model_lgb, oof_lgb, pred_lgb = train_lgbm(train_lgb, test_lgb, model_lgb_params, features, cat, target)\n",
        "model_xgb, oof_xgb, pred_xgb = train_XGB(train_xgb, test_xgb, model_xgb_params, features_xgb, target)\n",
        "model_xgb2, oof_xgb2, pred_xgb2 = train_XGB(train_xgb2, test_xgb2, model_xgb2_params, features, target)\n",
        "\n",
        "# ======= Ensemble all ========\n",
        "oof_ensemble = (oof_lgb + oof_xgb + oof_xgb2 + oof_rf + oof_hist) / 5\n",
        "pred_ensemble = (pred_lgb + pred_xgb + pred_xgb2 + pred_rf + pred_hist) / 5\n",
        "\n",
        "# ======= Scoring ========\n",
        "y_true = train[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\n",
        "y_pred = train[[\"ID\"]].copy()\n",
        "y_pred[\"prediction\"] = oof_ensemble\n",
        "\n",
        "m = score(y_true, y_pred, \"ID\")\n",
        "print(f\"\\nOverall CV for KaplanMeier = {m}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8a2ea79",
      "metadata": {
        "id": "a8a2ea79"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "guflVDme10Oz",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "guflVDme10Oz"
      },
      "outputs": [],
      "source": [
        "!pip install lifelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aHpXkR0dUpN2",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aHpXkR0dUpN2"
      },
      "outputs": [],
      "source": [
        "from lifelines.utils import concordance_index\n",
        "\n",
        "def score_cindex(y_true, y_pred, id_column='ID'):\n",
        "    \"\"\"\n",
        "    Calculates C-Index for survival prediction.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true: DataFrame with columns [ID, event, time, ...]\n",
        "    - y_pred: DataFrame with columns [ID, prediction]\n",
        "    - id_column: Common ID column for matching\n",
        "\n",
        "    Returns:\n",
        "    - cindex score (higher is better)\n",
        "    \"\"\"\n",
        "    # Merge ground truth and predictions on the ID column\n",
        "    merged = y_true.merge(y_pred, on=id_column, how='left')\n",
        "\n",
        "    # Extract true event times, event indicators, and model predictions\n",
        "    times = merged['efs_time']     # Time to event or censoring\n",
        "    events = merged['efs']         # 1 = event occurred, 0 = censored\n",
        "    preds = merged['prediction']   # Model risk scores or predicted times\n",
        "\n",
        "    # Concordance index treats higher scores as higher risk → invert if needed\n",
        "    # Here we negate preds so that higher preds imply shorter survival\n",
        "    cindex = concordance_index(times, -preds, events)\n",
        "\n",
        "    return cindex\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lLjAKrrSUqTL",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lLjAKrrSUqTL"
      },
      "outputs": [],
      "source": [
        "# After making oof_ensemble\n",
        "y_true = train[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\n",
        "y_pred = train[[\"ID\"]].copy()\n",
        "y_pred[\"prediction\"] = oof_ensemble\n",
        "\n",
        "cindex_score = score_cindex(y_true, y_pred, \"ID\")\n",
        "print(f\"\\nOverall CV (C-Index) =\", cindex_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fcdcd7b",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2fcdcd7b"
      },
      "outputs": [],
      "source": [
        "sample_submission = pd.read_csv('/content/equity-post-HCT-survival-predictions/sample_submission.csv')\n",
        "submission = sample_submission.copy()\n",
        "submission['prediction'] = pred_ensemble*100\n",
        "submission.to_csv('./submission.csv', index=False)\n",
        "submission\n",
        "df=pd.read_csv('./submission.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6VuJNcWZga3c",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6VuJNcWZga3c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Actual values and predicted values\n",
        "actual = np.array([50, 50, 50])  # Replace with your actual values\n",
        "predicted = np.array([41.6, 62, 37.4])  # Replace with your predicted values\n",
        "\n",
        "# Calculate the Mean Absolute Percentage Error (MAPE)\n",
        "mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = 100 - mape\n",
        "\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")\n",
        "print(f\"Model Accuracy: {accuracy}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56IRbmakhdmy",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "56IRbmakhdmy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Model performance data\n",
        "data = {\n",
        "    'Model': [\n",
        "        'Random Forest',\n",
        "        'HistGBDT',\n",
        "        'LightGBM',\n",
        "        'XGBoost (v1)',\n",
        "        'XGBoost (v2, deeper)'\n",
        "    ],\n",
        "    'Mean RMSE': [\n",
        "        0.1982,\n",
        "        0.1946,\n",
        "        0.1926,\n",
        "        0.1935,\n",
        "        0.1938\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set a consistent plot style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Vertical bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model', y='Mean RMSE', data=df, palette='mako')\n",
        "plt.title('Model Comparison by Mean RMSE')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylim(0.19, 0.20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Horizontal bar chart (alternative view)\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(y='Model', x='Mean RMSE', data=df, palette='flare')\n",
        "plt.title('Model Comparison by Mean RMSE')\n",
        "plt.xlim(0.19, 0.20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 10381525,
          "sourceId": 70942,
          "sourceType": "competition"
        },
        {
          "sourceId": 211253469,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 211322530,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30822,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 175.408393,
      "end_time": "2025-01-25T13:34:34.113321",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-01-25T13:31:38.704928",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}